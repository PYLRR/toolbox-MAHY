{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import glob2\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.detection.association_geodesic import squarize\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "plt.style.use('classic')\n",
    "plt.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.size\": 10,\n",
    "    \"axes.titlesize\": 10,\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,\n",
    "    \"legend.fontsize\": 8,\n",
    "})\n",
    "from matplotlib import rc\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)\n",
    "import math\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from numpy.linalg import LinAlgError\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.patches as mpatches\n",
    "import cartopy.crs as ccrs\n",
    "from collections import Counter\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib.colors import Normalize\n",
    "from utils.data_reading.sound_data.station import StationsCatalog\n",
    "from utils.physics.sound_model.spherical_sound_model import GridSphericalSoundModel as GridSoundModel, MonthlyHomogeneousSphericalSoundModel as HomogeneousSoundModel\n",
    "from utils.detection.association_geodesic import compute_candidates, update_valid_grid, update_results, load_detections, compute_grids"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# paths\n",
    "CATALOG_PATH = \"/media/plerolland/akoustik/MAHY\"\n",
    "Pn_DETECTIONS_DIR = f\"../../../../data/detection/TiSSNet_Pn_raw_OBS-fixed\"\n",
    "DETECTIONS_DIR = f\"../../../../data/detection/i_TiSSNet_raw_OBS-fixed\"\n",
    "\n",
    "# sound model definition\n",
    "STATIONS = StationsCatalog(CATALOG_PATH).filter_out_undated().filter_out_unlocated()\n",
    "\n",
    "LAT_BOUNDS = [-13.4, -12.4]\n",
    "LON_BOUNDS = [45.25, 46.25]\n",
    "with open(\"../../../../data/detection/i_TiSSNet_raw_OBS-fixed/MAHY0/cache/grids_-13.4_-12.4_45.25_46.25_150_1_0.25_0.25.pkl\", \"rb\") as f:\n",
    "    GRID_TO_COORDS, TDoA, MAX_TDoA, TDoA_UNCERTAINTIES = pickle.load(f)\n",
    "GRID_TO_COORDS = np.array(GRID_TO_COORDS)\n",
    "Pn_BOUNDS = [(1_000,100_000), (-13.4,-12.4), (45.25,46.25)]\n",
    "with open(\"../../../../data/detection/TiSSNet_Pn_raw_OBS-fixed/MAHY0/cache/grids_1000_100000_-13.4_-12.4_45.25_46.25_100_100_1_0.1.pkl\", \"rb\") as f:\n",
    "    Pn_GRID_TO_COORDS, Pn_TDoA, Pn_MAX_TDoA, Pn_TDoA_UNCERTAINTIES, Pn_LATS, Pn_DEPTHS, Pn_TRAVEL_TIMES = pickle.load(f)\n",
    "Pn_GRID_TO_COORDS = np.array(Pn_GRID_TO_COORDS)"
   ],
   "id": "724af32e9cfd9325",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MIN_ASSOCIATION_SIZE = 3\n",
    "\n",
    "new_stations = {}\n",
    "idx_to_det = {}\n",
    "datasets = set([s.dataset for s in STATIONS])\n",
    "for dataset in datasets:\n",
    "    dets = glob2.glob(f\"{DETECTIONS_DIR}/{dataset}/cache/detections*.pkl\")[0]\n",
    "    with open(dets, \"rb\") as f:\n",
    "        DETECTIONS = pickle.load(f)\n",
    "    idx_det = 0\n",
    "    idx_to_det_local = {}\n",
    "    for idx, s in enumerate(DETECTIONS.keys()):\n",
    "        s.idx = idx  # indexes to store efficiently the associations\n",
    "        DETECTIONS[s] = list(DETECTIONS[s])\n",
    "        for i in range(len(DETECTIONS[s])):\n",
    "            DETECTIONS[s][i] = np.concatenate((DETECTIONS[s][i], [idx_det]))\n",
    "            idx_to_det_local[idx_det] = DETECTIONS[s][i]\n",
    "            idx_det += 1\n",
    "        DETECTIONS[s] = np.array(DETECTIONS[s])\n",
    "    new_stations[dataset] = list(DETECTIONS.keys())\n",
    "    idx_to_det[dataset] = idx_to_det_local\n",
    "\n",
    "Pn_new_stations = {}\n",
    "Pn_idx_to_det = {}\n",
    "for dataset in datasets:\n",
    "    dets = glob2.glob(f\"{Pn_DETECTIONS_DIR}/{dataset}/cache/detections*.pkl\")[0]\n",
    "    with open(dets, \"rb\") as f:\n",
    "        Pn_DETECTIONS = pickle.load(f)\n",
    "    Pn_idx_det = 0\n",
    "    Pn_idx_to_det_local = {}\n",
    "    for idx, s in enumerate(Pn_DETECTIONS.keys()):\n",
    "        s.idx = idx  # indexes to store efficiently the associations\n",
    "        Pn_DETECTIONS[s] = list(Pn_DETECTIONS[s])\n",
    "        for i in range(len(Pn_DETECTIONS[s])):\n",
    "            Pn_DETECTIONS[s][i] = np.concatenate((Pn_DETECTIONS[s][i], [Pn_idx_det]))\n",
    "            Pn_idx_to_det_local[Pn_idx_det] = Pn_DETECTIONS[s][i]\n",
    "            Pn_idx_det += 1\n",
    "        Pn_DETECTIONS[s] = np.array(Pn_DETECTIONS[s])\n",
    "    Pn_idx_to_det[dataset] = Pn_idx_to_det_local\n",
    "\n",
    "STATIONS = new_stations"
   ],
   "id": "51ea9deddd3ef7b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nb_per_coord = {n: [0]*len(GRID_TO_COORDS) for n in range(3, 5)}\n",
    "\n",
    "for dataset in tqdm(datasets):\n",
    "    asso_files = glob2.glob(f\"{DETECTIONS_DIR}/{dataset}/cache/associations_{MIN_ASSOCIATION_SIZE}*.pkl\")\n",
    "    for file in asso_files:\n",
    "        with open(file, \"rb\") as f:\n",
    "            associations = pickle.load(f)\n",
    "            for dets, valid_pts in associations:\n",
    "                for i in valid_pts:\n",
    "                    nb_per_coord[len(dets)][i] += 1\n",
    "\n",
    "\n",
    "dep_bounds = [35_000, 45_000]\n",
    "coords_2d = Pn_GRID_TO_COORDS[Pn_GRID_TO_COORDS[:, 0] == Pn_DEPTHS[0], 1:]\n",
    "Pn_coord_to_idx = {tuple(coord): idx for idx, coord in enumerate(coords_2d)}\n",
    "Pn_nb_per_coord = {n: [0]*len(coords_2d) for n in range(3, 5)}\n",
    "\n",
    "for dataset in datasets:\n",
    "    association_files = glob2.glob(f\"{Pn_DETECTIONS_DIR}/{dataset}/cache/associations_{1}_{MIN_ASSOCIATION_SIZE}_*.pkl\")\n",
    "    for file in association_files:\n",
    "        with open(file, \"rb\") as f:\n",
    "            associations = pickle.load(f)\n",
    "        for detections, valid_points in tqdm(associations):\n",
    "            valid_coords = Pn_GRID_TO_COORDS[valid_points[:,0].astype(np.int32)]\n",
    "            mask = (valid_coords[:, 0] > dep_bounds[0]) & (valid_coords[:, 0] < dep_bounds[1])\n",
    "            filtered_coords = valid_coords[mask]\n",
    "\n",
    "            done = {3:set(), 4:set()}\n",
    "            for coord in filtered_coords[:, 1:]:\n",
    "                idx = Pn_coord_to_idx.get(tuple(coord))\n",
    "                if idx is not None and idx not in done[len(detections)]:\n",
    "                    done[len(detections)].add(idx)\n",
    "                    Pn_nb_per_coord[len(detections)][idx] += 1\n",
    "\n",
    "S_df = pd.read_csv(\n",
    "    \"../../../../data/MAHY/lavayssiere_and_public.csv\", header=None, names=[\"date\",\"lat\",\"lon\",\"depth\",\"mb\"], parse_dates=[\"date\"]\n",
    ")\n",
    "\n",
    "i_df = pd.read_csv(\"../../../../data/MAHY/ALav_i.txt\", delim_whitespace=True)"
   ],
   "id": "71092fb6e194681",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.ticker as mticker\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "import matplotlib.patches as patches\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "fig = plt.figure()\n",
    "width_in = 5.5\n",
    "height_in = width_in/1.08\n",
    "fig.set_size_inches(width_in, height_in)\n",
    "proj = ccrs.PlateCarree()\n",
    "ax = plt.axes(projection=proj)\n",
    "\n",
    "lat_bounds, lon_bounds = (min(coords_2d[:,0]), max(coords_2d[:,0])), (min(coords_2d[:,1]), max(coords_2d[:,1]))\n",
    "hist, grid_lat, grid_lon = squarize(coords_2d, np.array(Pn_nb_per_coord[3]) + np.array(Pn_nb_per_coord[4]), lat_bounds, lon_bounds)\n",
    "im = ax.imshow(hist[::-1], extent=(lon_bounds[0],lon_bounds[1],lat_bounds[0],lat_bounds[1]), cmap=\"Blues\", vmin=0)\n",
    "\n",
    "lat_bins = np.linspace(lat_bounds[0], lat_bounds[1], 101)\n",
    "lon_bins = np.linspace(lon_bounds[0], lon_bounds[1], 101)\n",
    "X, Y = np.meshgrid(lat_bins, lon_bins)\n",
    "S_hist, _, _ = np.histogram2d(S_df['lat'], S_df['lon'], bins=[lat_bins, lon_bins])\n",
    "S_hist_smoothed = gaussian_filter(S_hist, sigma=1)\n",
    "x_centers = 0.5 * (lon_bins[:-1] + lon_bins[1:])  # lon\n",
    "y_centers = 0.5 * (lat_bins[:-1] + lat_bins[1:])  # lat\n",
    "X, Y = np.meshgrid(x_centers, y_centers)\n",
    "S_contours = ax.contour(X, Y, S_hist_smoothed, colors='black', linewidths=1.2, zorder=2, levels=[10, 30])\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, label='Number of associations', aspect=40, pad=0.02, shrink=0.73)\n",
    "\n",
    "gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='white', alpha=0.5, linestyle='--')\n",
    "gl.top_labels, gl.right_labels = False, False\n",
    "\n",
    "gl.xlocator = mticker.MultipleLocator(0.1)\n",
    "gl.ylocator = mticker.MultipleLocator(0.1)\n",
    "gl.xformatter = mticker.FuncFormatter(lambda x, _: f\"{x:.2f}°E\")\n",
    "gl.yformatter = mticker.FuncFormatter(lambda y, _: f\"{-y:.2f}°S\")\n",
    "for i, label in enumerate(ax.get_xticklabels()):\n",
    "    label.set_rotation(0)\n",
    "    if i % 2 == 1:\n",
    "        label.set_y(-0.035)\n",
    "    else:\n",
    "        label.set_y(-0.02)\n",
    "\n",
    "# Add stations\n",
    "for s_ in STATIONS[\"MAHY0\"]:\n",
    "    lat, lon = s_.get_pos()\n",
    "    ax.plot(lon, lat, 'x', transform=proj, markersize=10, markeredgewidth=1, color=\"black\")\n",
    "    if \"3\" in s_.name:\n",
    "        ax.text(\n",
    "            lon - 0.75 * 2.5 * (LON_BOUNDS[1] - LON_BOUNDS[0]) / 30,\n",
    "            lat + 1 * 1.2 * (LAT_BOUNDS[1] - LAT_BOUNDS[0]) / 50,\n",
    "            s_.name[:-2] + \"*\" + s_.name[-1], transform=proj, color='black', weight='bold', alpha=0.9\n",
    "        )\n",
    "    else:\n",
    "        ax.text(\n",
    "            lon -  1 * 1.2 * (LON_BOUNDS[1] - LON_BOUNDS[0]) / 30,\n",
    "            lat +  1 * 1.2 * (LAT_BOUNDS[1] - LAT_BOUNDS[0]) / 50,\n",
    "            s_.name[:-2] + \"*\" + s_.name[-1], transform=proj, color='black', weight='bold', alpha=0.9\n",
    "        )\n",
    "\n",
    "\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "\n",
    "plt.savefig(\n",
    "    f'../../../../data/MAHY/figures/Pn-map_proj.png',\n",
    "    dpi=500,\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0\n",
    ")"
   ],
   "id": "a7e75ce9fecd1ca0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib import cm\n",
    "from numpy import ma\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "import matplotlib.patches as patches\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "fig = plt.figure()\n",
    "width_in = 5.5\n",
    "height_in = width_in/1.08\n",
    "fig.set_size_inches(width_in, height_in)\n",
    "proj = ccrs.PlateCarree()\n",
    "ax = plt.axes(projection=proj)\n",
    "\n",
    "#### Pn\n",
    "# custom color map (to have transparency at low values)\n",
    "base_cmap = plt.cm.get_cmap('Blues', 256)\n",
    "colors = base_cmap(np.linspace(0, 1, 256))\n",
    "colors[:32, -1] = 0\n",
    "colors[32:64, -1] = np.linspace(0, 1, 32)\n",
    "cmap_with_alpha = ListedColormap(colors)\n",
    "# plot\n",
    "lat_bounds, lon_bounds = (min(coords_2d[:,0]), max(coords_2d[:,0])), (min(coords_2d[:,1]), max(coords_2d[:,1]))\n",
    "hist, grid_lat, grid_lon = squarize(coords_2d, np.array(Pn_nb_per_coord[3]) + np.array(Pn_nb_per_coord[4]), lat_bounds, lon_bounds)\n",
    "im = ax.imshow(hist[::-1], extent=(lon_bounds[0],lon_bounds[1],lat_bounds[0],lat_bounds[1]), cmap=cmap_with_alpha, vmin=0, zorder=1)\n",
    "cbar = plt.colorbar(im, ax=ax, label='Number of P-phase associations', aspect=40, pad=0.02, shrink=0.7)\n",
    "\n",
    "#### i\n",
    "# custom color map (to have transparency at low values)\n",
    "base_cmap = plt.cm.get_cmap('Reds', 256)\n",
    "colors = base_cmap(np.linspace(0, 1, 256))\n",
    "colors[:32, -1] = 0\n",
    "colors[32:64, -1] = np.linspace(0, 1, 32)\n",
    "cmap_with_alpha = ListedColormap(colors)\n",
    "# plot\n",
    "hist_2, _, _ = squarize(GRID_TO_COORDS, np.array(nb_per_coord[3]) + np.array(nb_per_coord[4]), lat_bounds, lon_bounds)\n",
    "hist_2 = ma.masked_where(hist_2 == 0, hist_2)\n",
    "im_2 = ax.imshow(hist_2[::-1], extent=(lon_bounds[0],lon_bounds[1],lat_bounds[0],lat_bounds[1]), cmap=cmap_with_alpha, vmin=0, zorder=2)\n",
    "cbar_2 = plt.colorbar(im_2, ax=ax, label='Number of H-wave associations', aspect=40, pad=0.02, shrink=0.7)\n",
    "\n",
    "\n",
    "#### OBS\n",
    "lat_bins = np.linspace(lat_bounds[0], lat_bounds[1], 101)\n",
    "lon_bins = np.linspace(lon_bounds[0], lon_bounds[1], 101)\n",
    "X, Y = np.meshgrid(lat_bins, lon_bins)\n",
    "S_hist, _, _ = np.histogram2d(S_df['lat'], S_df['lon'], bins=[lat_bins, lon_bins])\n",
    "S_hist_smoothed = gaussian_filter(S_hist, sigma=0.5)\n",
    "x_centers = 0.5 * (lon_bins[:-1] + lon_bins[1:])  # lon\n",
    "y_centers = 0.5 * (lat_bins[:-1] + lat_bins[1:])  # lat\n",
    "X, Y = np.meshgrid(x_centers, y_centers)\n",
    "S_contours = ax.contour(X, Y, S_hist_smoothed, colors='black', linewidths=0.75, alpha=0.5, zorder=2, levels=[10, 30])\n",
    "\n",
    "#### i LAVAY\n",
    "i_hist, _, _ = np.histogram2d(i_df['LATITUDE'], i_df['LONGITUDE'], bins=[lat_bins, lon_bins])\n",
    "i_hist_smoothed = gaussian_filter(i_hist, sigma=0.5)\n",
    "i_contours = ax.contour(X, Y, i_hist_smoothed, colors='gold', linewidths=0.75, alpha=0.5, zorder=2, levels=[10])\n",
    "\n",
    "# COAST\n",
    "ax.add_feature(cfeature.LAND, zorder=10, edgecolor='white', facecolor='lightgray')\n",
    "ax.add_feature(cfeature.COASTLINE, zorder=10, edgecolor='white', linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, zorder=10, edgecolor='white', linestyle=':', linewidth=0.5)\n",
    "ax.text(45.265, -12.72, \"Petite Terre\", fontsize=8, color='black')\n",
    "\n",
    "#### GRID\n",
    "gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.top_labels, gl.right_labels = False, False\n",
    "gl.xlocator = mticker.MultipleLocator(0.1)\n",
    "gl.ylocator = mticker.MultipleLocator(0.1)\n",
    "gl.xformatter = mticker.FuncFormatter(lambda x, _: f\"{x:.1f}°E\")\n",
    "gl.xlabel_style = {'fontsize': 8}\n",
    "gl.yformatter = mticker.FuncFormatter(lambda y, _: f\"{-y:.1f}°S\")\n",
    "gl.ylabel_style = {'fontsize': 8}\n",
    "for i, label in enumerate(ax.get_xticklabels()):\n",
    "    label.set_rotation(0)\n",
    "    if i % 2 == 1:\n",
    "        label.set_y(-0.035)\n",
    "    else:\n",
    "        label.set_y(-0.02)\n",
    "\n",
    "#### STATIONS\n",
    "for s_ in STATIONS[\"MAHY0\"]:\n",
    "    lat, lon = s_.get_pos()\n",
    "    ax.plot(lon, lat, 'x', transform=proj, markersize=10, markeredgewidth=1, color=\"black\")\n",
    "    if \"3\" in s_.name:\n",
    "        ax.text(\n",
    "            lon - 0.85 * 4.25 * (LON_BOUNDS[1] - LON_BOUNDS[0]) / 30,\n",
    "            lat + 1 * 1.6 * (LAT_BOUNDS[1] - LAT_BOUNDS[0]) / 50,\n",
    "            s_.name[:-2] + \"*\" + s_.name[-1], transform=proj, color='black', weight='bold', alpha=0.9, fontsize=8\n",
    "        )\n",
    "    else:\n",
    "        ax.text(\n",
    "            lon -  1 * 1.2 * (LON_BOUNDS[1] - LON_BOUNDS[0]) / 30,\n",
    "            lat +  1 * 1.6 * (LAT_BOUNDS[1] - LAT_BOUNDS[0]) / 50,\n",
    "            s_.name[:-2] + \"*\" + s_.name[-1], transform=proj, color='black', weight='bold', alpha=0.9, fontsize=8\n",
    "        )\n",
    "ax.plot(45.703, -12.906, marker=\"^\", color=\"red\", markersize=8, zorder=15)  # volcano\n",
    "\n",
    "\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.savefig(\n",
    "    f'../../../../data/MAHY/figures/map_proj.pdf',\n",
    "    dpi=500,\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0\n",
    ")"
   ],
   "id": "ccc67b80147f6882",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.ticker as mticker\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "import matplotlib.patches as patches\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "fig = plt.figure()\n",
    "width_in = 5.5/2\n",
    "height_in = width_in/1.11\n",
    "fig.set_size_inches(width_in, height_in)\n",
    "proj = ccrs.PlateCarree()\n",
    "ax = plt.axes(projection=proj)\n",
    "\n",
    "lat_bounds, lon_bounds = (min(GRID_TO_COORDS[:,0]), max(GRID_TO_COORDS[:,0])), (min(GRID_TO_COORDS[:,1]), max(GRID_TO_COORDS[:,1]))\n",
    "hist, grid_lat, grid_lon = squarize(GRID_TO_COORDS, np.array(nb_per_coord[3]) + np.array(nb_per_coord[4]), lat_bounds, lon_bounds)\n",
    "im = ax.imshow(hist[::-1], extent=(lon_bounds[0],lon_bounds[1],lat_bounds[0],lat_bounds[1]), cmap=\"inferno\", vmin=0)\n",
    "\n",
    "lat_bins = np.linspace(lat_bounds[0], lat_bounds[1], 101)\n",
    "lon_bins = np.linspace(lon_bounds[0], lon_bounds[1], 101)\n",
    "X, Y = np.meshgrid(lat_bins, lon_bins)\n",
    "S_hist, _, _ = np.histogram2d(S_df['lat'], S_df['lon'], bins=[lat_bins, lon_bins])\n",
    "S_hist_smoothed = gaussian_filter(S_hist, sigma=2)\n",
    "x_centers = 0.5 * (lon_bins[:-1] + lon_bins[1:])  # lon\n",
    "y_centers = 0.5 * (lat_bins[:-1] + lat_bins[1:])  # lat\n",
    "X, Y = np.meshgrid(x_centers, y_centers)\n",
    "S_contours = ax.contour(X, Y, S_hist, colors='black', linewidths=1.2, zorder=2, levels=[10, 30])\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, label='Number of associations', aspect=40, pad=0.02, shrink=0.89)\n",
    "\n",
    "gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='white', alpha=0.5, linestyle='--')\n",
    "gl.top_labels, gl.right_labels = False, False\n",
    "\n",
    "gl.xlocator = mticker.MultipleLocator(0.1)\n",
    "gl.ylocator = mticker.MultipleLocator(0.1)\n",
    "gl.xformatter = mticker.FuncFormatter(lambda x, _: f\"{x:.2f}°E\")\n",
    "gl.yformatter = mticker.FuncFormatter(lambda y, _: f\"{-y:.2f}°S\")\n",
    "for i, label in enumerate(ax.get_xticklabels()):\n",
    "    label.set_rotation(0)\n",
    "    if i % 2 == 1:\n",
    "        label.set_y(-0.035)\n",
    "    else:\n",
    "        label.set_y(-0.02)\n",
    "\n",
    "# Add stations\n",
    "for s_ in STATIONS[\"MAHY0\"]:\n",
    "    lat, lon = s_.get_pos()\n",
    "    ax.plot(lon, lat, 'x', transform=proj, markersize=10, markeredgewidth=1, color=\"gold\")\n",
    "    if \"3\" in s_.name:\n",
    "        ax.text(\n",
    "            lon - 2.05 * 2.5 * (LON_BOUNDS[1] - LON_BOUNDS[0]) / 30,\n",
    "            lat + 2 * 1.2 * (LAT_BOUNDS[1] - LAT_BOUNDS[0]) / 50,\n",
    "            s_.name[:-2] + \"*\" + s_.name[-1], transform=proj, color='gold', weight='bold', alpha=0.9\n",
    "        )\n",
    "    elif \"4\" in s_.name:\n",
    "        ax.text(\n",
    "            lon -  2 * 1.2 * (LON_BOUNDS[1] - LON_BOUNDS[0]) / 30,\n",
    "            lat +  1.55 * 1.2 * (LAT_BOUNDS[1] - LAT_BOUNDS[0]) / 50,\n",
    "            s_.name[:-2] + \"*\" + s_.name[-1], transform=proj, color='gold', weight='bold', alpha=0.9\n",
    "        )\n",
    "    else:\n",
    "        ax.text(\n",
    "            lon -  2 * 1.2 * (LON_BOUNDS[1] - LON_BOUNDS[0]) / 30,\n",
    "            lat +  2 * 1.2 * (LAT_BOUNDS[1] - LAT_BOUNDS[0]) / 50,\n",
    "            s_.name[:-2] + \"*\" + s_.name[-1], transform=proj, color='gold', weight='bold', alpha=0.9\n",
    "        )\n",
    "ax.plot(-12.906, 45.703, marker=\"^\", color=\"red\", markersize=8, zorder=15)  # volcano\n",
    "\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "\n",
    "plt.savefig(\n",
    "    f'../../../../data/MAHY/figures/i-map_proj.pdf',\n",
    "    dpi=500,\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0\n",
    ")"
   ],
   "id": "85d970426341ecf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "min_size_display = 3\n",
    "log = False\n",
    "weights = np.array([\n",
    "    np.sum([nb_per_coord[n][i] for n in range(min_size_display,5)])\n",
    "    for i in range(len(GRID_TO_COORDS))\n",
    "])\n",
    "sq = squarize(GRID_TO_COORDS, weights, LAT_BOUNDS, LON_BOUNDS, size=1500)[0]\n",
    "if log:\n",
    "    sq[sq < 1] = 1\n",
    "    sq = np.log10(sq)\n",
    "\n",
    "# Create lat/lon grids\n",
    "lat_grid = np.linspace(LAT_BOUNDS[0], LAT_BOUNDS[1], sq.shape[0])\n",
    "lon_grid = np.linspace(LON_BOUNDS[0], LON_BOUNDS[1], sq.shape[1])\n",
    "lon2d, lat2d = np.meshgrid(lon_grid, lat_grid)\n",
    "\n",
    "# Cartopy plot\n",
    "fig = plt.figure()\n",
    "width_in = 5.5\n",
    "height_in = width_in/1.11\n",
    "fig.set_size_inches(width_in, height_in)\n",
    "\n",
    "proj = ccrs.PlateCarree()\n",
    "ax = plt.axes(projection=proj)\n",
    "ax.set_extent([LON_BOUNDS[0], LON_BOUNDS[1], LAT_BOUNDS[0], LAT_BOUNDS[1]], crs=proj)\n",
    "\n",
    "# Add continents and coastlines\n",
    "ax.add_feature(cfeature.LAND, zorder=10, edgecolor='white', facecolor='lightgray')\n",
    "ax.add_feature(cfeature.COASTLINE, zorder=10, edgecolor='white', linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, zorder=10, edgecolor='white', linestyle=':', linewidth=0.5)\n",
    "\n",
    "# Plot data\n",
    "c = ax.pcolormesh(lon2d, lat2d, sq, cmap=\"inferno\", transform=proj, vmin=100, vmax=1200)\n",
    "\n",
    "# Add stations\n",
    "for s_ in STATIONS[\"MAHY0\"]:\n",
    "    lat, lon = s_.get_pos()\n",
    "    ax.plot(lon, lat, 'x', transform=proj, markersize=10, markeredgewidth=1, color=\"gold\")\n",
    "    if \"3\" in s_.name:\n",
    "        ax.text(\n",
    "            lon - 2.5 * (LON_BOUNDS[1] - LON_BOUNDS[0]) / 30,\n",
    "            lat + 1.2 * (LAT_BOUNDS[1] - LAT_BOUNDS[0]) / 50,\n",
    "            s_.name[:-2] + \"*\" + s_.name[-1], transform=proj, color='gold', weight='bold', alpha=0.9\n",
    "        )\n",
    "    else:\n",
    "        ax.text(\n",
    "            lon - 1.2 * (LON_BOUNDS[1] - LON_BOUNDS[0]) / 30,\n",
    "            lat + 1.2 * (LAT_BOUNDS[1] - LAT_BOUNDS[0]) / 50,\n",
    "            s_.name[:-2] + \"*\" + s_.name[-1], transform=proj, color='gold', weight='bold', alpha=0.9\n",
    "        )\n",
    "\n",
    "# Ticks\n",
    "gl = ax.gridlines(draw_labels=True, crs=proj, linewidth=0.5, color='gray', alpha=0.5)\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(c, ax=ax, orientation='vertical', fraction=0.0415/2, aspect=20*2.08, pad=0.02)\n",
    "cbar.set_label(f'Number of associations{\" (log)\" if log else \"\"}', rotation=270, labelpad=15)\n",
    "# add \">\" before the highest value\n",
    "ticks = cbar.get_ticks()\n",
    "ticks_labels = [str(int(t)) for t in ticks[:-1]] + [r'$\\geq$' + str(int(ticks[-1]))]\n",
    "cbar.set_ticklabels(ticks_labels)\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "\n",
    "plt.savefig(\n",
    "    f'../../../../data/MAHY/figures/i-map_proj_min-{min_size_display}_{\"log\" if log else \"\"}.pdf',\n",
    "    dpi=500,\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0\n",
    ")"
   ],
   "id": "f8b088baf4d5b01c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lat_bounds = [-15,-10]\n",
    "lat_bounds_NW = [-12.6,-12.45]\n",
    "lat_bounds = [-12.9,-12.8]\n",
    "lon_bounds = [45,47]\n",
    "lon_bounds_NW = [45.45,45.6]\n",
    "lon_bounds = [45.6,45.75]\n",
    "\n",
    "kept = []\n",
    "kept_NW = []\n",
    "nb_i = 0\n",
    "for dataset in tqdm(datasets):\n",
    "    asso_files = glob2.glob(f\"{DETECTIONS_DIR}/{dataset}/cache/associations_{MIN_ASSOCIATION_SIZE}*.pkl\")\n",
    "    for file in asso_files:\n",
    "        with open(file, \"rb\") as f:\n",
    "            associations = pickle.load(f)\n",
    "\n",
    "            for dets, valid_pts in associations:\n",
    "                nb_i += 1\n",
    "                pts = np.array([GRID_TO_COORDS[p] for p in valid_pts])\n",
    "                if np.any((pts[:,0] > lat_bounds[0]) & (pts[:,0] < lat_bounds[1]) & (pts[:,1] > lon_bounds[0]) & (pts[:,1] < lon_bounds[1])):\n",
    "                    dates = [idx_to_det[dataset][d[1]][0] for d in dets]\n",
    "                    kept.append(dates[0] + np.mean([d-dates[0] for d in dates]))\n",
    "                if np.any((pts[:,0] > lat_bounds_NW[0]) & (pts[:,0] < lat_bounds_NW[1]) & (pts[:,1] > lon_bounds_NW[0]) & (pts[:,1] < lon_bounds_NW[1])):\n",
    "                    dates = [idx_to_det[dataset][d[1]][0] for d in dets]\n",
    "                    kept_NW.append(dates[0] + np.mean([d-dates[0] for d in dates]))\n",
    "\n",
    "print(nb_i, len(kept), len(kept_NW), \"H-waves\")\n",
    "\n",
    "Pn_kept = []\n",
    "nb_P = 0\n",
    "for dataset in tqdm(datasets):\n",
    "    #asso_files = glob2.glob(f\"{Pn_DETECTIONS_DIR[:-10]}_repicked/{dataset}/cache/associations_1_{MIN_ASSOCIATION_SIZE}*.pkl\")\n",
    "    asso_files = glob2.glob(f\"{Pn_DETECTIONS_DIR}/{dataset}/cache/associations_1_{MIN_ASSOCIATION_SIZE}*.pkl\")\n",
    "    for file in asso_files:\n",
    "        with open(file, \"rb\") as f:\n",
    "            associations = pickle.load(f)\n",
    "            for dets, valid_pts in associations:\n",
    "                nb_P += 1\n",
    "                dates = [Pn_idx_to_det[dataset][d[1]][0] for d in dets]\n",
    "                Pn_kept.append(dates[0] + np.mean([d-dates[0] for d in dates]))\n",
    "\n",
    "print(nb_P, len(Pn_kept), \"P\")\n",
    "\n",
    "# 41867 3694 H\n",
    "# 28194 28194 P\n",
    "# 26018 26018 P"
   ],
   "id": "772620c100e574ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hours = [dt.hour for dt in kept_NW]\n",
    "\n",
    "print(len(hours))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, sharex=True, tight_layout=True)\n",
    "width_in = 5.5\n",
    "height_in = width_in / 2\n",
    "fig.set_size_inches(width_in, height_in)\n",
    "\n",
    "\n",
    "plt.hist(hours, bins=24, range=(0, 24), edgecolor='black', color=\"#4c72b0\", alpha=0.8)\n",
    "plt.xticks(np.arange(0, 24))\n",
    "ax.tick_params(axis=\"x\", top=False)\n",
    "plt.xlim(0,24)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.ylim(-1, None)\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.ylabel(\"Number of events\")\n",
    "\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.savefig(\"/home/plerolland/Bureau/toolbox/data/MAHY/figures/i_NW_hourly-hist.pdf\", dpi=500, bbox_inches='tight', pad_inches=0)"
   ],
   "id": "803ce5c4ccf6aef5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "detections_i = {}\n",
    "record_bounds = {}\n",
    "\n",
    "c = 0\n",
    "\n",
    "STATIONS = StationsCatalog(CATALOG_PATH).filter_out_undated().filter_out_unlocated()\n",
    "for s in tqdm(STATIONS):\n",
    "    s_mooring_line = s.name[:-2] + s.name[-1]\n",
    "    record_bounds.setdefault(s_mooring_line, []).append((s.date_start, s.date_end))\n",
    "    path = f\"{DETECTIONS_DIR}/{s.dataset}/{s.dataset}_{s.name}.pkl\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "    c += len(d)\n",
    "    s_mooring_line = s.name[:-2] + s.name[-1]\n",
    "    detections_i.setdefault(s_mooring_line, []).extend(d)\n",
    "\n",
    "print(c)\n",
    "\n",
    "STATIONS = list(detections_i.keys())\n",
    "for s in STATIONS:\n",
    "    detections_i[s] = np.array(detections_i[s])\n",
    "\n",
    "detections_Pn = {}\n",
    "\n",
    "c = 0\n",
    "\n",
    "STATIONS = StationsCatalog(CATALOG_PATH).filter_out_undated().filter_out_unlocated()\n",
    "for s in tqdm(STATIONS):\n",
    "    s_mooring_line = s.name[:-2] + s.name[-1]\n",
    "    path = f\"{Pn_DETECTIONS_DIR}/{s.dataset}/{s.dataset}_{s.name}.pkl\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "    c += len(d)\n",
    "    s_mooring_line = s.name[:-2] + s.name[-1]\n",
    "    detections_Pn.setdefault(s_mooring_line, []).extend(d)\n",
    "\n",
    "print(c)\n",
    "\n",
    "STATIONS = list(detections_Pn.keys())\n",
    "for s in STATIONS:\n",
    "    detections_Pn[s] = np.array(detections_Pn[s])"
   ],
   "id": "d1de0e333261875e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "def dates_format(x, pos):\n",
    "    dt = mdates.num2date(x)\n",
    "    return r'\\shortstack{%s\\\\%s}' % (dt.strftime('%d/%m'), dt.strftime('%Y'))\n",
    "\n",
    "all_bounds = [b for bounds in record_bounds.values() for b in bounds]\n",
    "global_start = min(start for start, _ in all_bounds)\n",
    "global_end = max(end for _, end in all_bounds)\n",
    "\n",
    "n_stations = len(detections_i)\n",
    "\n",
    "######### Pn\n",
    "\n",
    "kept_nums = mdates.date2num(Pn_kept)\n",
    "start_global_hist = mdates.num2date(min(kept_nums)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "end_global_hist = mdates.num2date(max(kept_nums)).replace(hour=0, minute=0, second=0, microsecond=0) + datetime.timedelta(weeks=1)\n",
    "week_bins = mdates.drange(start_global_hist, end_global_hist, datetime.timedelta(weeks=1))\n",
    "\n",
    "fig, axes = plt.subplots(n_stations + 1, 2, sharex=True, tight_layout=True)\n",
    "width_in = 5.5\n",
    "height_in = 1.25 * (n_stations + 1)\n",
    "fig.set_size_inches(width_in, height_in)\n",
    "\n",
    "min_start = np.min([s.date_start for s in StationsCatalog(CATALOG_PATH).filter_out_undated().filter_out_unlocated()])\n",
    "max_end = np.max([s.date_end for s in StationsCatalog(CATALOG_PATH).filter_out_undated().filter_out_unlocated()])\n",
    "bin_t = round(((max_end - min_start).total_seconds() / (86400*7)))\n",
    "\n",
    "for i, (station, ax) in enumerate(zip(detections_Pn.keys(), axes[:-1,0])):  # sauf dernier axe\n",
    "    df = pd.DataFrame(detections_Pn[station], columns=['time', 'prob'])\n",
    "    times = pd.to_datetime(df['time'])\n",
    "    time_nums = mdates.date2num(times)\n",
    "\n",
    "    ax.hist(time_nums, bins=bin_t, color='royalblue', edgecolor='royalblue', zorder=0)\n",
    "\n",
    "    ax.xaxis_date()\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.yaxis.grid(color=\"darkslategray\", alpha=0.5, zorder=1)\n",
    "    if i == 3 or i==0:\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(1000))\n",
    "    ax.set_title(f\"P-phase detections -  {station[:-1]}*{station[-1]}\")\n",
    "\n",
    "    valid_periods = record_bounds[station]\n",
    "    invalid_periods = []\n",
    "    current = global_start\n",
    "    for start, end in sorted(valid_periods):\n",
    "        if current < start:\n",
    "            invalid_periods.append((current, start))\n",
    "        current = max(current, end)\n",
    "    if current < global_end:\n",
    "        invalid_periods.append((current, global_end))\n",
    "\n",
    "    for start, end in invalid_periods:\n",
    "        ax.axvspan(start, end, color='dimgrey', zorder=10)\n",
    "\n",
    "    ax.text(0.45 if station[-1] != \"3\" else 0.25, 0.8, f'$\\Sigma = {len(time_nums)}$', transform=ax.transAxes, zorder=100, va='top', ha='left')\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "ax = axes[-1,0]\n",
    "ax.hist(kept_nums, bins=week_bins, color=\"darkblue\", edgecolor=\"darkblue\")\n",
    "ax.yaxis.grid(color=\"darkslategray\", alpha=0.5, zorder=1)\n",
    "\n",
    "ax.xaxis_date()\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth=[1]))\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_major_formatter(mticker.FuncFormatter(dates_format))\n",
    "ax.tick_params(axis=\"x\", direction=\"out\", which=\"major\", labelsize=9, length=6, width=1, top=False)\n",
    "ax.tick_params(axis=\"x\", direction=\"out\", which=\"minor\", length=3, top=False)\n",
    "ax.set_xlim(global_start, global_end)\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.yaxis.set_major_locator(MultipleLocator(200))\n",
    "ax.set_title(\"P-phase associations\")\n",
    "ax.text(0.45, 0.8, f'$\\Sigma = {len(kept_nums)}$', transform=ax.transAxes, zorder=100, va='top', ha='left')\n",
    "\n",
    "interval = mdates.MonthLocator(interval=12)\n",
    "start_tick = mdates.num2date(axes[-1,0].get_xticks()[0]).replace(tzinfo=None)\n",
    "xtick_locs = interval.tick_values(start_tick - datetime.timedelta(days=30), global_end)\n",
    "\n",
    "for ax in axes[:,0]:\n",
    "    for xtick in xtick_locs:\n",
    "        ax.axvline(xtick, color='black', linestyle='--', linewidth=0.6, zorder=11)\n",
    "\n",
    "\n",
    "########### i\n",
    "\n",
    "kept_nums = mdates.date2num(kept)\n",
    "start_global_hist = mdates.num2date(min(kept_nums)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "end_global_hist = mdates.num2date(max(kept_nums)).replace(hour=0, minute=0, second=0, microsecond=0) + datetime.timedelta(weeks=1)\n",
    "week_bins = mdates.drange(start_global_hist, end_global_hist, datetime.timedelta(weeks=1))\n",
    "\n",
    "min_start = np.min([s.date_start for s in StationsCatalog(CATALOG_PATH).filter_out_undated().filter_out_unlocated()])\n",
    "max_end = np.max([s.date_end for s in StationsCatalog(CATALOG_PATH).filter_out_undated().filter_out_unlocated()])\n",
    "bin_t = round(((max_end - min_start).total_seconds() / (86400*7)))\n",
    "\n",
    "for i, (station, ax) in enumerate(zip(detections_i.keys(), axes[:-1,1])):  # sauf dernier axe\n",
    "    df = pd.DataFrame(detections_i[station], columns=['time', 'prob'])\n",
    "    times = pd.to_datetime(df[df['prob']>0.3]['time'])\n",
    "    time_nums = mdates.date2num(times)\n",
    "\n",
    "    ax.hist(time_nums, bins=bin_t, color='red', edgecolor='red', zorder=0)\n",
    "\n",
    "\n",
    "    ax.xaxis_date()\n",
    "    ax.yaxis.grid(color=\"darkslategray\", alpha=0.5, zorder=1)\n",
    "    if i == 3:\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(1000))\n",
    "    ax.set_title(f\"H-wave detections - {station[:-1]}*{station[-1]}\")\n",
    "\n",
    "    valid_periods = record_bounds[station]\n",
    "    invalid_periods = []\n",
    "    current = global_start\n",
    "    for start, end in sorted(valid_periods):\n",
    "        if current < start:\n",
    "            invalid_periods.append((current, start))\n",
    "        current = max(current, end)\n",
    "    if current < global_end:\n",
    "        invalid_periods.append((current, global_end))\n",
    "\n",
    "    for start, end in invalid_periods:\n",
    "        ax.axvspan(start, end, color='dimgrey', zorder=10)\n",
    "\n",
    "    ax.text(0.45 if station[-1] != \"3\" else 0.25, 0.8, f'$\\Sigma = {len(time_nums)}$', transform=ax.transAxes, zorder=100, va='top', ha='left')\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "ax = axes[-1,1]\n",
    "ax.hist(kept_nums, bins=week_bins, color=\"maroon\", edgecolor=\"maroon\")\n",
    "ax.yaxis.grid(color=\"darkslategray\", alpha=0.5, zorder=1)\n",
    "\n",
    "ax.xaxis_date()\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth=[1]))\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_major_formatter(mticker.FuncFormatter(dates_format))\n",
    "ax.tick_params(axis=\"x\", direction=\"out\", which=\"major\", labelsize=9, length=6, width=1, top=False)\n",
    "ax.tick_params(axis=\"x\", direction=\"out\", which=\"minor\", length=3, top=False)\n",
    "ax.set_xlim(global_start, global_end)\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_title(\"H-wave associations\")\n",
    "ax.text(0.45, 0.8, f'$\\Sigma = {len(kept_nums)}$', transform=ax.transAxes, zorder=100, va='top', ha='left')\n",
    "\n",
    "interval = mdates.MonthLocator(interval=12)\n",
    "start_tick = mdates.num2date(axes[-1,1].get_xticks()[0]).replace(tzinfo=None)\n",
    "xtick_locs = interval.tick_values(start_tick - datetime.timedelta(days=30), global_end)\n",
    "\n",
    "for ax in axes[:,1]:\n",
    "    for xtick in xtick_locs:\n",
    "        ax.axvline(xtick, color='black', linestyle='--', linewidth=0.6, zorder=11)\n",
    "\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.savefig(\"/home/plerolland/Bureau/toolbox/data/MAHY/figures/i-Pn_detections_associations_hist.pdf\", dpi=500, bbox_inches='tight', pad_inches=0)"
   ],
   "id": "834cd6a6b372053e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Pn_h = pd.read_csv(\"../../../../data/MAHY/loc_3D/P_association_catalog.csv\", parse_dates=[\"date\"]).sort_values(\"mb\")\n",
    "Pn_s = pd.read_csv(\n",
    "    \"../../../../data/MAHY/lavayssiere_and_public.csv\", header=None, names=[\"date\",\"lat\",\"lon\",\"depth\",\"mb\"], parse_dates=[\"date\"])\n",
    "\n",
    "\n",
    "start_date, end_date = datetime.datetime(2020, 8, 1), datetime.datetime(2024, 10, 1)\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "availability = pd.Series(0, index=all_dates)\n",
    "for start, end in itertools.chain.from_iterable(record_bounds.values()):\n",
    "    start = datetime.datetime(start.year, start.month, start.day)\n",
    "    end = min(end_date, datetime.datetime(end.year, end.month, end.day))\n",
    "    dates_available = pd.date_range(start=start, end=end, freq='D')\n",
    "    availability[dates_available] += 1\n",
    "availability[availability > 4] = 4\n",
    "\n",
    "\n",
    "window_days = 10\n",
    "overlap = 0.25\n",
    "step_days = window_days * (1 - overlap)\n",
    "\n",
    "current_date = start_date\n",
    "dates_middle_bis = []\n",
    "counts_h, counts_s = [], []\n",
    "\n",
    "with tqdm(total=(end_date - start_date).days // step_days) as pbar:\n",
    "    while current_date + pd.Timedelta(days=window_days) <= end_date:\n",
    "        window_start = current_date\n",
    "        window_end = current_date + pd.Timedelta(days=window_days)\n",
    "\n",
    "        # h\n",
    "        mask = (Pn_h[\"date\"] >= window_start) & (Pn_h[\"date\"] < window_end)\n",
    "        n_events = mask.sum()\n",
    "        counts_h.append(n_events)\n",
    "\n",
    "        # s\n",
    "        mask = (Pn_s[\"date\"] >= window_start) & (Pn_s[\"date\"] < window_end)\n",
    "        n_events = mask.sum()\n",
    "        counts_s.append(n_events)\n",
    "\n",
    "        dates_middle_bis.append(window_start + pd.Timedelta(days=window_days/2))\n",
    "        current_date += pd.Timedelta(days=step_days)\n",
    "        pbar.update(1)\n",
    "\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(5.5, 3), sharex=True)\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "\n",
    "# --- (ax1) ---\n",
    "ax1.plot(dates_middle_bis, counts_h, '-', color='royalblue')\n",
    "ax1.set_ylabel(f\"Number of events\")\n",
    "ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "ax1.set_xlim(datetime.datetime(2020, 8, 1), datetime.datetime(2024, 10, 1))\n",
    "ax1.xaxis_date()\n",
    "ax1.xaxis.set_major_locator(mdates.MonthLocator(bymonth=[1]))\n",
    "ax1.xaxis.set_minor_locator(mdates.MonthLocator(bymonth=range(1, 13)))\n",
    "ax1.xaxis.set_major_formatter(dates_format)\n",
    "ax1.tick_params(axis='x', labelrotation=0, top=False, bottom=False)\n",
    "ax1.text(0.955, 0.955, 'AuH', transform=ax1.transAxes, fontsize=12, fontweight='bold', va='top', ha='right')\n",
    "\n",
    "ax2.plot(dates_middle_bis, counts_s, '-', color='black')\n",
    "ax2.set_ylabel(f\"Number of events\")\n",
    "ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "ax2.tick_params(axis='x', top=False)\n",
    "ax2.set_xlabel(\"Date\")\n",
    "ax2.text(0.99, 0.94, 'Reference', transform=ax2.transAxes, fontsize=12, fontweight='bold', va='top', ha='right')\n",
    "\n",
    "# ----- availability ------\n",
    "colors = plt.cm.Greys(np.linspace(0, 0.8, 5)[::-1])\n",
    "cmap = ListedColormap(colors)\n",
    "norm = BoundaryNorm(boundaries=[0,1,2,3,4,5], ncolors=cmap.N)\n",
    "current_level = availability.iloc[0]\n",
    "start_segment = availability.index[0]\n",
    "for date, level in zip(availability.index, availability):\n",
    "    if level != current_level:\n",
    "        ax1.axvspan(start_segment, date, color=cmap(norm(current_level)), alpha=1, zorder=0)\n",
    "        current_level = level\n",
    "        start_segment = date\n",
    "ax1.axvspan(start_segment, availability.index[-1], color=cmap(norm(current_level)), alpha=1, zorder=0)\n",
    "\n",
    "# ----- colorbar ------\n",
    "cbar_ax = fig.add_axes([0.92, 0.55, 0.02, 0.35])  # position (left, bottom, width, height)\n",
    "sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, cax=cbar_ax, ticks=[0.5,1.5,2.5,3.5,4.5], orientation='vertical')\n",
    "cbar.ax.tick_params(which='both', length=0)\n",
    "cbar.ax.set_yticklabels(['0','1','2','3','4'][::-1])\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_y(0)\n",
    "cbar.set_label(\"Missing stations\")\n",
    "\n",
    "\n",
    "# vertical lines\n",
    "shift_date = datetime.datetime(2021,6,1)\n",
    "x_fig = ax1.transData.transform((mdates.date2num(shift_date), 0))[0]\n",
    "x_fig = fig.transFigure.inverted().transform((x_fig, 0))[0]\n",
    "fig.lines.append(plt.Line2D([x_fig, x_fig], [0.1, 0.9], transform=fig.transFigure,\n",
    "                            color='red', linewidth=1.5, zorder=15, alpha=0.5))\n",
    "y_phase = 0.47\n",
    "bar_height = 0.01\n",
    "x_start = fig.transFigure.inverted().transform(ax1.transData.transform((mdates.date2num(start_date), 0)))[0]\n",
    "x_shift = fig.transFigure.inverted().transform(ax1.transData.transform((mdates.date2num(shift_date), 0)))[0]\n",
    "x_end = fig.transFigure.inverted().transform(ax1.transData.transform((mdates.date2num(end_date), 0)))[0]\n",
    "fig.lines.append(plt.Line2D([x_start, x_shift], [y_phase, y_phase], transform=fig.transFigure,\n",
    "                            color='black', linewidth=1.2, zorder=15))\n",
    "fig.text((x_start + x_shift)/2, y_phase + 0.01, \"Phase I\", ha='center', va='bottom', fontweight='bold')\n",
    "fig.lines.append(plt.Line2D([x_start, x_start], [y_phase - bar_height, y_phase + bar_height], transform=fig.transFigure,\n",
    "                            color='black', linewidth=1.2, zorder=15))\n",
    "fig.lines.append(plt.Line2D([x_shift, x_shift], [y_phase - bar_height, y_phase + bar_height], transform=fig.transFigure,\n",
    "                            color='black', linewidth=1.2, zorder=15))\n",
    "fig.lines.append(plt.Line2D([x_shift, x_end], [y_phase, y_phase], transform=fig.transFigure,\n",
    "                            color='black', linewidth=1.2, zorder=15))\n",
    "fig.lines.append(plt.Line2D([x_end, x_end], [y_phase - bar_height, y_phase + bar_height], transform=fig.transFigure,\n",
    "                            color='black', linewidth=1.2, zorder=15))\n",
    "fig.text((x_shift + x_end)/2, y_phase + 0.01, \"Phase II\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "\n",
    "EQ1 = datetime.datetime(2021,3,3,1,59)  # 39 km m = 4.5\n",
    "EQ2 = datetime.datetime(2022,4,14,12,57)  # 46 km m = 4.1\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    for date in Pn_s[Pn_s[\"mb\"] > 4][\"date\"]:\n",
    "        ax.axvline(date, color='black', linestyle='--', linewidth=1, zorder=10, alpha=0.5)\n",
    "    ax.axvline(EQ1, color='black', linestyle='--', linewidth=1, zorder=10, alpha=0.5)\n",
    "    ax.axvline(EQ2, color='black', linestyle='--', linewidth=1, zorder=10, alpha=0.5)\n",
    "\n",
    "\n",
    "plt.savefig(\n",
    "    f'../../../../data/MAHY/figures/time_distrib.pdf',\n",
    "    dpi=500,\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0\n",
    ")"
   ],
   "id": "a872bd4285af76b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "i_h = pd.read_csv(\"../../../../data/MAHY/loc_3D/i_association_catalog_Center.csv\", parse_dates=[\"date\"])\n",
    "i_h[\"day_of_year\"] = i_h[\"date\"].dt.dayofyear\n",
    "i_h_filtered = i_h[(i_h[\"day_of_year\"] >= 295) & (i_h[\"day_of_year\"] <= 345)]\n",
    "\n",
    "grouped = i_h_filtered.groupby(\"day_of_year\").agg(\n",
    "    count=(\"date\", \"count\"),\n",
    "    lat=(\"latitude\", \"mean\")\n",
    ").reset_index()\n",
    "norm = Normalize(vmin=grouped[\"lat\"].min(), vmax=grouped[\"lat\"].max())\n",
    "cmap = cm.get_cmap(\"Reds\")\n",
    "colors = cmap(norm(grouped[\"lat\"]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5.5, 3))\n",
    "ax.bar(grouped[\"day_of_year\"], grouped[\"count\"], color=colors, edgecolor=\"black\", width=1)\n",
    "\n",
    "ax.set_xlabel(\"Julian day since January 1st, 2020\")\n",
    "ax.set_ylabel(\"Number of events\")\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "ax.set_xlim(295, 345)\n",
    "ax.set_yticks([0, 50, 100])\n",
    "ax.tick_params(axis=\"x\", direction=\"out\", length=6, width=1, top=False)\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # hack pour colorbar sans image\n",
    "cbar = fig.colorbar(sm, ax=ax, orientation='vertical', label=\"Average latitude (°S)\", pad=0.02)\n",
    "cbar.ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.1f\"))\n",
    "\n",
    "plt.savefig(\n",
    "    f'../../../../data/MAHY/figures/time_distrib_H.pdf',\n",
    "    dpi=500,\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0\n",
    ")"
   ],
   "id": "f16dc24ba11f8b9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# availability\n",
    "cmap = cm.Greys_r"
   ],
   "id": "1db8f2373bdd205e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.plot(availability.index, availability)",
   "id": "8a7fb00359710132",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "900d1835b9b1acdc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
